{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_9MsvpC84VkUXNscr2raIdjz2HgAaVU_","timestamp":1667945185022}],"authorship_tag":"ABX9TyPNJMgjue+E24aVstAJeeZs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# <center> Make a Copy of This Notebook </center>"],"metadata":{"id":"npdBflV2c04B"}},{"cell_type":"markdown","source":["# Feature Engineering\n","\n","In this notebook you perform feature engineering to:\n","1. Handle missing values\n","2. "],"metadata":{"id":"Lmp3JoP2nQzp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fu6bkefYnK-j"},"outputs":[],"source":["# Imports\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import make_column_transformer, make_column_selector\n","from sklearn.pipeline import make_pipeline\n","from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, \\\n","precision_score, recall_score, accuracy_score, f1_score, ConfusionMatrixDisplay, \\\n","classification_report\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","source":["# Useful Functions"],"metadata":{"id":"Vrdzw2ow2f7q"}},{"cell_type":"code","source":["def eval_regression(true, pred, name='Model'):\n","  scores = pd.DataFrame()\n","  scores['Model Name'] = [name]\n","  scores['RMSE'] = [np.sqrt(mean_squared_error(true, pred))]\n","  scores['MAE'] = [mean_absolute_error(true, pred)]\n","  scores['R2'] = [r2_score(true, pred)]\n","  return scores\n","\n","def eval_classification(true, pred, name='Model'):\n","  \"\"\"shows classification_report and confusion matrix\n","  for the model predictions\"\"\"\n","  \n","  print(name, '\\n')\n","  print(classification_report(true, pred))\n","  ConfusionMatrixDisplay.from_predictions(true, pred)\n","  plt.show()\n","\n","  scores = pd.DataFrame()\n","  scores['Model Name'] = [name]\n","  scores['Precision'] = [precision_score(true, pred)]\n","  scores['Recall'] = [recall_score(true, pred)]\n","  scores['F1 Score'] = [f1_score(true, pred)]\n","  scores['Accuracy'] = [accuracy_score(true, pred)]\n","\n","  return scores"],"metadata":{"id":"pr2Oayig2iFR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data\n","\n","Today we will use data about housing sales in Melbourne, Australia. \n","\n","## Your job is to predict the sale price of the house."],"metadata":{"id":"TdIxE4xgNU3m"}},{"cell_type":"code","source":["# load data\n","df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQnwAtoM6edkuZ4Xncjx_wnZjN6zcWRtBZdK9wfQwW6AzXCGhOdjvTQrtbsEU5-LxKdOmz5FAtw66tc/pub?gid=1132845715&single=true&output=csv')\n","df_original = df.copy()\n","\n","display(df.head())\n","print(df.shape)"],"metadata":{"id":"FJb74mnanWAY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Explore and clean the data\n","1. Drop the 'Address column', it's too specific.\n","2. Drop any duplicates\n","3. Look for missing values.  If you want to drop rows or columns, now is the time.  Wait on imputing until after the split.\n","4. Check summary statistics to look for outliers."],"metadata":{"id":"j5Ep8q1T02el"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"Kk8M7SQ7Shw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check for duplicates\n","df.duplicated().sum()"],"metadata":{"id":"jpf0LSXexRPy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice the values in the 'Unique' rows.  Which categorical columns have high cardinality (Many different categories)?"],"metadata":{"id":"9XtYMbRa7CsR"}},{"cell_type":"code","source":["# check summary statistics\n","df.describe(include='all')"],"metadata":{"id":"mPLcxeYt0jMd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Price'].describe()"],"metadata":{"id":"pBY0S2qvt8fy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# explore numeric distributions\n","for col in df.select_dtypes('number'):\n","  print('\\n', col, '\\n')\n","  df[col].plot(kind='box')\n","  plt.show()"],"metadata":{"id":"xjFlm0hdxmYl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Feature Engineering\n","\n","What would you do to improve this dataset?\n","\n","### Some Ideas:\n","1. Remove outliers\n","2. Change the distribution with np.log, np.sqrt, np.cbrt\n","3. Bin features or target with .replace or .apply\n","4. Combine features\n","5. Extract hour, day, or month from datetime\n","6. Encode data: one-hot encoding, ordinal encoding, target encoding\n","7. Parse strings\n","8. Try different imputation strategies"],"metadata":{"id":"b5mB-62ixhOE"}},{"cell_type":"code","source":["# check for missing values\n","df.isna().sum()"],"metadata":{"id":"VjksV-Zn0gbl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Handle Missing Values\n","Ideas:\n","1. Drop columns\n","2. Drop rows\n","3. Wait and impute later"],"metadata":{"id":"rdPGK8PsSmp9"}},{"cell_type":"code","source":["# \n","\n"],"metadata":{"id":"fhapJs89SqJ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Engineer Categorical Features\n","\n","Ideas:\n","1. Extract day, month, and/or year from the 'Date' column\n","2. Remove columns with high cardinality\n","3. Bin categories to reduce cardinality\n","4. Combine categorical features\n","5. Split categorical features\n"],"metadata":{"id":"qXFO-KPBMnze"}},{"cell_type":"code","source":["for col in df.select_dtypes('object'):\n","  print(col, df[col].nunique())"],"metadata":{"id":"9zHP5ChwqBCx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TJ4fkXjZMq7_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Engineer Numeric Features\n","\n","Possible Options:\n","1. Remove outliers\n","2. Reshape distributions with np.log, np.sqrt, or np.cbrt\n","3. Bin a numeric feature to make it nominal or ordinal\n","\n"],"metadata":{"id":"2tWbnRK2NEdW"}},{"cell_type":"code","source":[],"metadata":{"id":"CpB_Z7OIbVk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mTIYzT7SbVDU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Validation Split"],"metadata":{"id":"Pr5J0t2d7pnw"}},{"cell_type":"markdown","source":["# (optional) 4. Engineer the Target\n","\n","Options:\n","1. Transform the target with np.log, np.sqrt, np.cbrt\n","2. Bin the target to make this a classification problem"],"metadata":{"id":"UUW0DP7cMDZH"}},{"cell_type":"code","source":[],"metadata":{"id":"MhIJyEABMF5n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Modeling:\n","\n","1. Create a Base Model on the original data\n","2. Create the same model type and fit it on your engineered data\n","3. Compare the performance of each model."],"metadata":{"id":"ZKU4SCm9Rq40"}},{"cell_type":"markdown","source":["### Original features from before feature engineering"],"metadata":{"id":"C1e93B8IVFi9"}},{"cell_type":"code","source":["X_og = df_original.drop(columns='Price')\n","y_og = df_original['Price']\n","\n","X_train_og, X_test_og, y_train_og, y_test_og = train_test_split(X_og, y_og, \n","                                                                random_state=42)"],"metadata":{"id":"XYC0mHHZVEpV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Uncomment and run the cell below if you binned the target above"],"metadata":{"id":"6ztQO7XhV7a1"}},{"cell_type":"code","source":["# mean_price = y_train_og.mean()\n","# y_train_og = y_train_og.apply(lambda x: 1 if x > mean_price else 0)\n","# y_test_og = y_test_og.apply(lambda x: 1 if x > mean_price else 0)"],"metadata":{"id":"Kh61VQ-GV0oE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Preprocessing\n","scaler = StandardScaler()\n","ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n","\n","median_imputer = SimpleImputer(strategy='median')\n","missing_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n","\n","cat_cols = make_column_selector(dtype_include='object')\n","num_cols = make_column_selector(dtype_include='number')\n","\n","num_pipe = make_pipeline(median_imputer, scaler)\n","cat_pipe = make_pipeline(missing_imputer, ohe)\n","\n","processor = make_column_transformer((num_pipe, num_cols), (cat_pipe, cat_cols))\n","print(processor.fit_transform(X_train, y_train).shape)"],"metadata":{"id":"mz2B32mvRtOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instantiate and fit a model\n","base_model = ## Choose a model of the appropriate type (regression or classification)\n","\n","base_pipe = make_pipeline(processor, base_model)\n","base_pipe.fit(X_train_og, y_train_og)\n","\n","train_pred = base_pipe.predict(X_train_og)\n","test_pred = base_pipe.predict(X_test_og)"],"metadata":{"id":"Wkl0rTGdRtOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate model\n","# train_scores = \n","\n","# test_scores = \n","\n","scores = pd.concat([train_scores, test_scores])\n","scores"],"metadata":{"id":"coKLazA9GppI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modeling: Engineered Data\n","\n","Use your engineered data to fit a new model of the same time as your base model.\n","\n","You might also do some more engineering here as well, if you want.\n","\n","Ideas:\n","1. Different encoders\n","2. Different imputation strategies\n","3. Different preprocessing, like scaling, PCA, or PolynomialFeatures"],"metadata":{"id":"P4KsHBlGEXl7"}},{"cell_type":"code","source":["X = df.drop(columns=['Price'])\n","y = df['Price']\n","\n","X_train, X_test, y_train, y_test =  train_test_split(X, y, random_state=42)"],"metadata":{"id":"NZOXt2eftIjK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.head()"],"metadata":{"id":"8mGqSSs3u9l5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Preprocessor\n"],"metadata":{"id":"kxA6zJEjUmXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create and fit model\n","\n","# Make Predictions"],"metadata":{"id":"Ye-HXybZUmR1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluate model\n","# train_scores = Your Code\n","\n","# test_scores = Your Code\n","\n","scores = pd.concat([train_scores, test_scores])\n","scores"],"metadata":{"id":"wIXBr92CRtOw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# If you have extra time:\n","\n","Try other feature engineering strategies"],"metadata":{"id":"hEJzu7pgb26e"}},{"cell_type":"code","source":[],"metadata":{"id":"9rBvx7leU2R9"},"execution_count":null,"outputs":[]}]}